# Document QA API

## ðŸŽ¯ Purpose

A cloud-native backend service built with **FastAPI** that allows users to upload documents (PDF/TXT/DOCX), process their contents into semantic embeddings, and answer natural language questions grounded in those documents using large language models (LLMs) and vector similarity search.

This project demonstrates a real-world retrieval-augmented question-answering (RAG) backend, with authentication, document ingestion, vector search, and AI integration.


## ðŸ›  Tech Stack

- FastAPI (async REST API, OpenAPI)
- Python 3.14+
- MongoDB (text, metadata & ownership)
- FAISS (vector similarity search)
- OpenAI API (embeddings & LLM)
- JWT authentication
- Pytest


## ðŸš€ Features

- Authenticated REST API (JWT)
- Document upload and processing (PDF, TXT, DOCX)
- Text extraction and chunking
- Embedding generation with OpenAI (or other providers)
- Vector search for semantic retrieval
- Question answering via context-grounded LLM calls
- Async FastAPI endpoints and dependency injection
- Clean architecture with services and schemas
- Fully documented via automatic OpenAPI / Swagger


## ðŸ§  Architecture Overview

User
â†“ (HTTP)
FastAPI API
â”œâ”€â”€ Auth (JWT)
â”œâ”€â”€ Documents (upload / list / delete)
â”œâ”€â”€ QA (question â†’ answer)
â”‚
â”œâ”€â”€ Text Parser (pdf/txt/docx)
â”œâ”€â”€ Chunker
â”œâ”€â”€ Embeddings (OpenAI / LLM provider)
â””â”€â”€ Vector Search (FAISS or other store)
â†³ retrieve relevant chunks
â†³ send context + question to LLM for answer


## ðŸ“¦ Installation

> Python 3.10+ recommended

```bash
git clone https://github.com/nicojapas/document-qa-api.git
cd document-qa-api
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
```

Set your environment variables:

GEMINI_AI_API_KEY (or other LLM/embedding provider)
MONGODB_URI


ðŸ“Œ Running Locally
Start the API with fastapi:

fastapi dev app/main.py

Visit the API docs: http://127.0.0.1:8000/docs

Automatic OpenAPI/Swagger makes testing the endpoints easy.


ðŸ§© API Endpoints
ðŸ”‘ Auth
Endpoint	Method	Description
/api/v1/auth/register	POST	Register new user
/api/v1/auth/login	POST	Login and receive JWT

ðŸ“„ Documents
Endpoint	Method	Description
/api/v1/documents	POST	Upload & process document
/api/v1/documents	GET	List user documents
/api/v1/documents/{id}	DELETE	Delete document

Uploaded files are parsed into text, chunked, and indexed for semantic retrieval.

ðŸ§  Question Answering
Endpoint	Method	Description
/api/v1/qa	POST	Ask a question about a document

Example request:

{
  "document_id": "abc123",
  "question": "What are the key findings?"
}
Answer responses are generated by retrieving relevant chunks and passing them with the question to the LLM.


ðŸ§ª Tests
Basic Pytest coverage exists for:

API routes

Auth logic

Document ingestion

QA pipeline

ðŸ§  How It Works (simplified)

User uploads a PDF/TXT/DOCX

Backend extracts text and splits into chunks

For each chunk, an embedding is generated

Vectors are indexed for semantic similarity matching

User asks a question

The backend:

Embeds the question

Retrieves nearest-neighbor text chunks

Passes question + context to the LLM

Returns answer

This approach uses retrieval-augmented generation (RAG) to make LLM answers factual and grounded. 


ðŸ§  Design Decisions
Storage

MongoDB stores text chunks, metadata and ownership

Embeddings are stored in a vector index (e.g., FAISS, not in MongoDB itself)

Models

LLM calls are abstracted so you can switch providers later


ðŸ’¬ Feedback & Contribution
This is a personal project; contributions are welcome via issues or PRs!

ðŸ“„ License
MIT License
Â© 2026 NicolÃ¡s Japas